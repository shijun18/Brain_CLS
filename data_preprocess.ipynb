{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape 128, mean is 0.130451 , std is 0.222160.\n",
      "Image shape 168, mean is 0.069808 , std is 0.166033.\n",
      "Image shape 256, mean is 0.077046 , std is 0.188026.\n",
      "Image shape 336, mean is 0.065723 , std is 0.163424.\n",
      "Resized Image shape 128, mean is 0.105393 , std is 0.203002.\n",
      "Resized Image shape 168, mean is 0.105781 , std is 0.202969.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "def get_pngs(path):\n",
    "    pngs = glob(os.path.join(path,\"*.png\"))\n",
    "    return pngs\n",
    "\n",
    "def load_data(path):\n",
    "    pil_img = Image.open(path).convert('L')\n",
    "    return np.array(pil_img)\n",
    "\n",
    "def get_all_imgs(pngs):\n",
    "    img_dict = {}\n",
    "    all_imgs = []\n",
    "    \n",
    "    for png in pngs:\n",
    "        img_arr = load_data(png)\n",
    "        all_imgs.append(img_arr)\n",
    "        \n",
    "        idx = int(img_arr.shape[0])\n",
    "        if idx in img_dict:\n",
    "            img_dict[idx].append(img_arr)\n",
    "        else:\n",
    "            img_dict[idx] = [img_arr]\n",
    "    \n",
    "    return img_dict,all_imgs\n",
    "\n",
    "def cal_mean_std(arr):\n",
    "    return np.mean(arr/255), np.std(arr/255)\n",
    "\n",
    "def get_all_pngs():\n",
    "    pngs = []\n",
    "\n",
    "    pngs += get_pngs(\"/staff/shijun/torch_projects/Brain_CLS/dataset/pre_data/train/AD\")\n",
    "    pngs += get_pngs(\"/staff/shijun/torch_projects/Brain_CLS/dataset/pre_data/train/CN\")\n",
    "    pngs += get_pngs(\"/staff/shijun/torch_projects/Brain_CLS/dataset/pre_data/test/AD&CN\")\n",
    "        \n",
    "    return pngs\n",
    "\n",
    "def resize(img, new_shape):\n",
    "    resize_factor = np.array(new_shape) / img.shape\n",
    "    img = zoom(img, resize_factor, mode='nearest', order=1)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def concat_imgs(imgs, shape):\n",
    "    all_imgs = None\n",
    "    for img in imgs:\n",
    "        new_img = resize(img,shape)\n",
    "        \n",
    "        if all_imgs is not None:\n",
    "            all_imgs = np.concatenate([all_imgs,new_img],axis=0)\n",
    "        else:\n",
    "            all_imgs = new_img\n",
    "    return all_imgs\n",
    "\n",
    "def main():\n",
    "    \n",
    "    pngs = get_all_pngs()\n",
    "    img_dict, all_imgs = get_all_imgs(pngs)\n",
    "\n",
    "    for key in img_dict.keys():\n",
    "        mean,std = cal_mean_std(np.array(img_dict[key]))\n",
    "        print(\"Image shape %d, mean is %f , std is %f.\"%(key,mean,std))\n",
    "        \n",
    "    imgs_128 = concat_imgs(all_imgs,128)\n",
    "    imgs_168 = concat_imgs(all_imgs,168)\n",
    "    \n",
    "    \n",
    "    print(\"Resized Image shape 128, mean is %f , std is %f.\"% cal_mean_std(imgs_128))\n",
    "    print(\"Resized Image shape 168, mean is %f , std is %f.\"% cal_mean_std(imgs_168))\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
